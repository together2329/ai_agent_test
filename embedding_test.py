#!/usr/bin/env python3
"""
ê³ ê¸‰ Embedding ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Dockerìš©)
- ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€
- ì‹œê°í™” í¬í•¨
- ìƒì„¸í•œ ë¶„ì„
"""

import numpy as np
from sentence_transformers import SentenceTransformer
import torch
import logging
import json
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Optional, Dict, Any
from tqdm import tqdm
import os
from datetime import datetime
from pathlib import Path

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
RESULTS_DIR = Path("results")
RESULTS_DIR.mkdir(exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DockerEmbeddingTester:
    """Docker í™˜ê²½ìš© í™•ì¥ëœ ì„ë² ë”© í…ŒìŠ¤í„°"""
    
    def __init__(self, 
                 model_name: str = 'sentence-transformers/all-MiniLM-L6-v2',
                 device: Optional[str] = None,
                 batch_size: int = 32):
        
        self.model_name = model_name
        self.batch_size = batch_size
        self.test_results = {}
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
            
        logger.info(f"Using device: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer(model_name, device=self.device)
        self.embedding_dimension = self.model.get_sentence_embedding_dimension()
        
        logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
        logger.info(f"ğŸ“ ì„ë² ë”© ì°¨ì›: {self.embedding_dimension}")
        
    def run_comprehensive_tests(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ suite ì‹¤í–‰"""
        print("\nğŸ§ª ì¢…í•© ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*50)
        
        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        self.test_single_embedding()
        self.test_batch_embedding()
        self.test_uvm_error_analysis()
        self.test_similarity_search()
        self.benchmark_performance()
        self.generate_visualizations()
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
        
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ëŠ” {RESULTS_DIR} ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    
    def test_single_embedding(self):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
        print("\n=== ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ===")
        
        test_text = "UVM_ERROR: Sequence timeout occurred in testbench component"
        embedding = self.model.encode(test_text, convert_to_numpy=True)
        
        results = {
            "input_text": test_text,
            "embedding_shape": embedding.shape,
            "embedding_dtype": str(embedding.dtype),
            "embedding_norm": float(np.linalg.norm(embedding)),
            "embedding_mean": float(np.mean(embedding)),
            "embedding_std": float(np.std(embedding)),
            "first_5_values": embedding[:5].tolist()
        }
        
        self.test_results["single_embedding"] = results
        
        print(f"âœ… ì…ë ¥: {test_text}")
        print(f"ğŸ“Š ì„ë² ë”© shape: {embedding.shape}")
        print(f"ğŸ“ˆ L2 norm: {results['embedding_norm']:.4f}")
        
    def test_batch_embedding(self):
        """ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
        print("\n=== ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ===")
        
        # ë‹¤ì–‘í•œ UVM ì—ëŸ¬ë“¤
        test_texts = [
            "UVM_ERROR: Sequence timeout in driver component",
            "UVM_FATAL: Null pointer access in scoreboard", 
            "UVM_WARNING: Phase timeout in test sequence",
            "UVM_ERROR: Protocol violation detected in monitor",
            "UVM_ERROR: Transaction mismatch in comparator",
            "UVM_FATAL: Memory allocation failed in testbench",
            "UVM_WARNING: Clock frequency mismatch detected",
            "UVM_ERROR: Interface handshake failure",
            "UVM_FATAL: Configuration object not found",
            "UVM_WARNING: Deprecated function usage detected"
        ]
        
        embeddings = self.embed_texts(test_texts, show_progress=True)
        
        # í†µê³„ ê³„ì‚°
        results = {
            "num_texts": len(test_texts),
            "embedding_shape": embeddings.shape,
            "texts": test_texts,
            "embedding_stats": {
                "mean_norm": float(np.mean(np.linalg.norm(embeddings, axis=1))),
                "std_norm": float(np.std(np.linalg.norm(embeddings, axis=1))),
                "dimension": int(embeddings.shape[1])
            }
        }
        
        self.test_results["batch_embedding"] = results
        
        print(f"âœ… ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸: {len(test_texts)}ê°œ")
        print(f"ğŸ“Š ì„ë² ë”© ë°°ì—´: {embeddings.shape}")
        
    def test_uvm_error_analysis(self):
        """UVM ì—ëŸ¬ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        print("\n=== UVM ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ ===")
        
        # ì—ëŸ¬ ìœ í˜•ë³„ ìƒ˜í”Œ
        error_categories = {
            "Timeout": [
                "UVM_ERROR: Sequence timeout in driver",
                "UVM_WARNING: Phase timeout detected", 
                "UVM_ERROR: Transaction timeout occurred"
            ],
            "Protocol": [
                "UVM_ERROR: Protocol violation in handshake",
                "UVM_ERROR: Interface protocol mismatch",
                "UVM_FATAL: Protocol error in bus transaction"
            ],
            "Memory": [
                "UVM_FATAL: Null pointer exception",
                "UVM_FATAL: Memory allocation failed",
                "UVM_ERROR: Buffer overflow detected"
            ],
            "Configuration": [
                "UVM_ERROR: Configuration object not found",
                "UVM_WARNING: Invalid configuration parameter",
                "UVM_FATAL: Configuration database corrupted"
            ]
        }
        
        category_embeddings = {}
        
        for category, texts in error_categories.items():
            embeddings = self.embed_texts(texts, show_progress=False)
            category_embeddings[category] = embeddings
            
            # ì¹´í…Œê³ ë¦¬ ë‚´ í‰ê·  ì„ë² ë”©
            avg_embedding = np.mean(embeddings, axis=0)
            
            print(f"ğŸ“‚ {category}: {len(texts)}ê°œ ì—ëŸ¬")
            
        # ì¹´í…Œê³ ë¦¬ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        category_similarities = self.compute_category_similarities(category_embeddings)
        
        self.test_results["uvm_error_analysis"] = {
            "categories": list(error_categories.keys()),
            "category_similarities": category_similarities,
            "error_samples": error_categories
        }
        
    def test_similarity_search(self):
        """ìœ ì‚¬ë„ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\n=== ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
        
        # UVM ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤
        uvm_docs = [
            "UVM sequence generates constrained random stimulus for verification",
            "Driver component sends transactions to DUT through virtual interface",
            "Monitor passively observes interface signals and creates transactions", 
            "Scoreboard compares predicted and actual DUT responses",
            "Agent encapsulates driver, monitor, and sequencer in reusable unit",
            "Factory enables runtime creation and configuration of UVM objects",
            "Phasing provides synchronization and ordering of testbench activities",
            "Configuration database stores and retrieves testbench parameters",
            "Transaction class models protocol-specific data and operations",
            "Virtual interface provides abstraction layer for signal connections"
        ]
        
        doc_embeddings = self.embed_texts(uvm_docs, show_progress=False)
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "sequence timeout problem",
            "driver interface error",
            "scoreboard comparison failure",
            "monitor sampling issue"
        ]
        
        search_results = {}
        
        for query in test_queries:
            query_embedding = self.model.encode(query, convert_to_numpy=True)
            similarities = self.compute_similarity(query_embedding, doc_embeddings)
            
            # ìƒìœ„ 3ê°œ ê²°ê³¼
            top_indices = np.argsort(similarities)[::-1][:3]
            
            results = []
            for idx in top_indices:
                results.append({
                    "document": uvm_docs[idx],
                    "similarity": float(similarities[idx])
                })
                
            search_results[query] = results
            
            print(f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
            for i, result in enumerate(results, 1):
                print(f"   {i}. ({result['similarity']:.4f}) {result['document'][:50]}...")
                
        self.test_results["similarity_search"] = search_results
        
    def benchmark_performance(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ===")
        
        import time
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_sizes = [10, 50, 100, 500, 1000]
        performance_results = {}
        
        for size in test_sizes:
            test_texts = [f"UVM test sentence number {i} for performance evaluation." 
                         for i in range(size)]
            
            start_time = time.time()
            embeddings = self.embed_texts(test_texts, show_progress=False)
            end_time = time.time()
            
            elapsed = end_time - start_time
            throughput = size / elapsed
            
            performance_results[size] = {
                "elapsed_time": elapsed,
                "throughput": throughput,
                "texts_per_second": throughput
            }
            
            print(f"ğŸ“Š {size:4d} í…ìŠ¤íŠ¸: {elapsed:.2f}ì´ˆ, {throughput:.1f} í…ìŠ¤íŠ¸/ì´ˆ")
            
        self.test_results["performance"] = performance_results
        
    def generate_visualizations(self):
        """ì‹œê°í™” ìƒì„±"""
        print("\n=== ì‹œê°í™” ìƒì„± ì¤‘ ===")
        
        # 1. ì„±ëŠ¥ ì°¨íŠ¸
        self.plot_performance()
        
        # 2. ì„ë² ë”© ë¶„í¬ íˆíŠ¸ë§µ  
        self.plot_embedding_heatmap()
        
        # 3. ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        self.plot_similarity_matrix()
        
        print("ğŸ“ˆ ì‹œê°í™” ì™„ë£Œ!")
        
    def plot_performance(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œê°í™”"""
        if "performance" not in self.test_results:
            return
            
        perf_data = self.test_results["performance"]
        sizes = list(perf_data.keys())
        throughputs = [perf_data[size]["throughput"] for size in sizes]
        
        plt.figure(figsize=(10, 6))
        plt.plot(sizes, throughputs, 'b-o', linewidth=2, markersize=8)
        plt.xlabel('Number of Texts')
        plt.ylabel('Throughput (texts/second)')
        plt.title('Embedding Performance Benchmark')
        plt.grid(True, alpha=0.3)
        plt.savefig(RESULTS_DIR / 'performance_benchmark.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    def plot_embedding_heatmap(self):
        """ì„ë² ë”© ë¶„í¬ íˆíŠ¸ë§µ"""
        if "batch_embedding" not in self.test_results:
            return
            
        # ë°°ì¹˜ ì„ë² ë”© ë°ì´í„° ì¬ìƒì„± (ì‹œê°í™”ìš©)
        test_texts = self.test_results["batch_embedding"]["texts"]
        embeddings = self.embed_texts(test_texts, show_progress=False)
        
        # ì²« 50ê°œ ì°¨ì›ë§Œ ì‹œê°í™”
        plt.figure(figsize=(12, 8))
        sns.heatmap(embeddings[:, :50], 
                   cmap='coolwarm', 
                   center=0,
                   xticklabels=False,
                   yticklabels=[f"Text {i+1}" for i in range(len(test_texts))])
        plt.title('Embedding Distribution Heatmap (First 50 dimensions)')
        plt.xlabel('Embedding Dimensions')
        plt.ylabel('Input Texts')
        plt.savefig(RESULTS_DIR / 'embedding_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    def plot_similarity_matrix(self):
        """ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì‹œê°í™”"""
        if "batch_embedding" not in self.test_results:
            return
            
        test_texts = self.test_results["batch_embedding"]["texts"]
        embeddings = self.embed_texts(test_texts, show_progress=False)
        
        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        similarity_matrix = np.dot(embeddings, embeddings.T)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(similarity_matrix, 
                   annot=True, 
                   fmt='.3f',
                   cmap='Blues',
                   square=True,
                   xticklabels=[f"T{i+1}" for i in range(len(test_texts))],
                   yticklabels=[f"T{i+1}" for i in range(len(test_texts))])
        plt.title('Text Similarity Matrix')
        plt.xlabel('Texts')
        plt.ylabel('Texts')
        plt.savefig(RESULTS_DIR / 'similarity_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    def compute_category_similarities(self, category_embeddings: Dict[str, np.ndarray]) -> Dict:
        """ì¹´í…Œê³ ë¦¬ ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        categories = list(category_embeddings.keys())
        similarities = {}
        
        for i, cat1 in enumerate(categories):
            for j, cat2 in enumerate(categories):
                if i <= j:
                    continue
                    
                # ê° ì¹´í…Œê³ ë¦¬ì˜ í‰ê·  ì„ë² ë”©
                avg1 = np.mean(category_embeddings[cat1], axis=0)
                avg2 = np.mean(category_embeddings[cat2], axis=0)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                similarity = np.dot(avg1, avg2) / (np.linalg.norm(avg1) * np.linalg.norm(avg2))
                similarities[f"{cat1}-{cat2}"] = float(similarity)
                
        return similarities
        
    def embed_texts(self, texts: List[str], show_progress: bool = True) -> np.ndarray:
        """ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        if not texts:
            return np.array([])
            
        embeddings = []
        
        for i in tqdm(range(0, len(texts), self.batch_size), 
                     disable=not show_progress,
                     desc="Generating embeddings"):
            batch = texts[i:i + self.batch_size]
            batch_embeddings = self.model.encode(
                batch,
                convert_to_numpy=True,
                show_progress_bar=False
            )
            embeddings.append(batch_embeddings)
            
        return np.vstack(embeddings)
    
    def compute_similarity(self, query_embedding: np.ndarray, 
                          doc_embeddings: np.ndarray) -> np.ndarray:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        doc_norms = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)
        similarities = np.dot(doc_norms, query_norm)
        return similarities
        
    def save_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ê²°ê³¼ ì €ì¥
        results_file = RESULTS_DIR / f"embedding_test_results_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
            
        # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_summary_report(timestamp)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_file}")
        
    def generate_summary_report(self, timestamp: str):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_file = RESULTS_DIR / f"embedding_test_summary_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Embedding Test Summary Report\n\n")
            f.write(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Model**: {self.model_name}\n")
            f.write(f"**Device**: {self.device}\n")
            f.write(f"**Embedding Dimension**: {self.embedding_dimension}\n\n")
            
            # ì„±ëŠ¥ ìš”ì•½
            if "performance" in self.test_results:
                f.write("## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n\n")
                perf_data = self.test_results["performance"]
                for size, metrics in perf_data.items():
                    f.write(f"- {size} texts: {metrics['throughput']:.1f} texts/sec\n")
                f.write("\n")
            
            # UVM ì—ëŸ¬ ë¶„ì„ ìš”ì•½
            if "uvm_error_analysis" in self.test_results:
                f.write("## UVM ì—ëŸ¬ ë¶„ì„\n\n")
                categories = self.test_results["uvm_error_analysis"]["categories"]
                f.write(f"ë¶„ì„ëœ ì—ëŸ¬ ì¹´í…Œê³ ë¦¬: {', '.join(categories)}\n\n")
            
            f.write("## íŒŒì¼ ëª©ë¡\n\n")
            f.write("- `embedding_test_results_*.json`: ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\n")
            f.write("- `performance_benchmark.png`: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì°¨íŠ¸\n")
            f.write("- `embedding_heatmap.png`: ì„ë² ë”© ë¶„í¬ íˆíŠ¸ë§µ\n")
            f.write("- `similarity_matrix.png`: í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤\n")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ³ Docker í™˜ê²½ Embedding í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # í™˜ê²½ ì •ë³´ ì¶œë ¥
    print(f"ğŸ Python version: {torch.__version__}")
    print(f"ğŸ”¥ PyTorch version: {torch.__version__}")
    print(f"ğŸ’» CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸš€ GPU device: {torch.cuda.get_device_name(0)}")
    
    # í…ŒìŠ¤í„° ì‹¤í–‰
    tester = DockerEmbeddingTester()
    tester.run_comprehensive_tests()

if __name__ == "__main__":
    main() 